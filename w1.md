---
layout: page
title: Wykład 1 - Small Data
mathjax: true
---

##  Data -> Small Data -> ...


Rozwój technologii informatycznych spowodował dostęp do niewyobrażalnych ilości nowego zasobu jakim są **ustrukturyzowane** jak i **nieustrukturyzowane** dane.

> Podaj przykład danych ustrukturyzowanych i nieustrukturyzowanych.

> Zna typy danych ustrukturyzowanych jak i nieustrukturyzowanych (K2A_W02, K2A_W04, O2_W04, O2_W07)

Dane przyczyniły się do powstania tysięcy nowych narzędzi do `generowania`, `zbierania`, `przechowywania` i `przetwarzania` informacji na niespotykaną dotąd skalę.

<img alt="Dane" src="../img/main.jpeg" align="center" />

Dane istnieją od bardzo dawna.

Z początku były one generowane w postaci obrazów w jaskiniach.
Po wprowadzeniu stystemu pisma można było prowadzić rachunkowości czy rejestry wszelakich rzeczy.
Informacje o najgłębszych jeziorach, najbardziej zaludnionych krajach, spis rzek itp. były publikowane w wielu rodzajach encyklopedii.
Przed powstaniem maszyn proces pomiarów i ręcznego zapisywania trwał bardzo długo i był bardzo pracochłonny. Dziś maszyny te dostępne są dla każdego człowieka w postaci komputerów czy telefonów.

Pojawienie się nowych wyzwań naukowych czy biznesowych staje się możliwe do realizacji dzięki budowie systemów opartych na `otwartym oprogramowaniu`, jak również dzięki wykorzystaniu domowych komputerów do wspomagania przetwarzania ogromnych ilości danych.

Nowe wyzwania to między innymi:
- inteligentna reklama tysięcy produktów dla milionów klientów,
- przetwarzanie danych o genach, RNA czy też białkach [genus](http://genus.fuw.edu.pl),
- inteligentne wykrywanie różnorodnych sposobów nadużyć wśród setek miliardów transakcji kart kredytowych,
- symulacje giełdowe oparte o tysiące instrumentów finansowych,
- rozpoznawanie miliardów przypadków efektów zderzeń protonów i produkcji cząstek elementarnych w LHC
- Bitcoin i inne waluty,
- komunikacja kwantowa,
- szyfrowanie kwantowe.

Dziś systemy takie jak [SAS](https://www.sas.com/pl_pl/home.html), [Apache Hadoop](https://hadoop.apache.org), [Apache Spark](https://spark.apache.org), [Apache Flink](https://flink.apache.org) czy [Microsoft Azure](https://azure.microsoft.com/pl-pl/) używane są na szeroką skalę w wielu instytucjach i firmach niemal w każdej dziedzinie.
Firmy te tworzą rozwiązania w bankowości, opiece zdrowotnej, naukach przyrodniczych, produkcji, sektorze publicznym czy sprzedaży.

Epoka danych stawia przed nami coraz to nowsze wyzwania związane nie tylko z ilością, ale i z czasem przetwarzania danych.


## Źródła danych


[Przepływ Big Data](https://www.internetlivestats.com)

- Działalność przedsiębiorstw i instytucji (banki, ubezpieczalnie, sieci handlowe, urzędy ...).

AT&T obsługuje miliardy połączeń dziennie.

Danych jest tyle, że nie zapisuje się ich a analizy prowadzone są `on the fly`.

- Ośrodki naukowe: $10^9$ rekordów danych astronomicznych, $10^2 \sim 10^3$ atrybutów w systemach diagnozy medycznej, 30 petabajtów rocznie w LHC.
Very Long Baseline Interferometry posiada 16 teleskopów, gdzie każdy produkuje 1 Gigabit/sec danych astronomicznych w czasie 25 dniowej sesji obserwacyjnej.
- Baza danych [BrainMaps](http://brainmaps.org) zawiera ponad 50 TB danych z mapami mózgów ssaków.
- Giełda NYSE 4-5 terabajtów dziennie
- Facebook - 7 petabajtów miesięcznie
- [Ancestry.com](https://www.ancestry.com) drzewo genealogiczne - $>10$ petabajtów danych
- Jednym z największych źródeł danych jest obecnie **sieć WEB** [WorldWideWebSize.com](http://www.worldwidewebsize.com).

(Thursday, 14 February, 2019) **at least 5.55 billion pages** .

(Friday, 14 August, 2020) **at least 5.72 billion pages** .

Od strony biznesowej:

- `Strumień danych` generowany przez pojedynczych ludzi szybko rośnie - [MyLifeBits](https://www.microsoft.com/en-us/research/project/mylifebits/)
- Największy wzrost danych przewiduje się w ramach IoT (czujniki, ślady GPS, transakcje handlowe, etc.)
- Przedsiębiorstwa nie mogą ograniczać się tylko do zarządzania własnymi danymi !!! SUKCES = umiejętność uzyskania wartości z firmowych danych.
- Jak przetwarzać publicznie dostępne dane?  Projekt [Public Data Sets](http://infochimps.org)
- Projekt [Astrometry](http://astrometry.net) - analiza zdjęć z Flickr w celu identyfikacji gwiazd i innych obiektów.


> Jak archiwizować osobiste informacje, które mogą trafić do powszechnego użytku ?


<img alt="Dane" src="../img/rys1.jpeg" align="center" />

## not to Big Data

> _,,Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so every one claims they are doing it.''_ — Dan Ariely, Professor of Psychology and Behavioral Economics, Duke University


### one, two, ... four V

1. Volume - Objętość - rozmiar danych produkowanych na całym świecie przyrasta w tempie wykładniczym. Huge amounts of data are being genereted every second - the email you send, Twitter, Facebook, or other social media, videos, pictures, SMS messages, call records and data from varied devices and sensors.
2. Velocity - Szybkość - tempo produkowania danych, szybkości ich przesyłania i przetwarzania.
3. Variety - Zróżnicowanie - tradycyjne dane kojarzą się nam z postacią alfanumeryczną złożoną z liter i cyfr. Obecnie mamy do dyspozycji obrazy, dźwięki, pliki wideo, strumienie danych z IoT
4. Veracity - Wiarygodność - Czy dane są kompletne i poprawne ? Czy obiektywnie odzwierciedlają rzeczywistość ? Czy są podstawą do podejmowania decyzji ?
5. Value - The value that the data actually holds. In the end, it's all about cost and benefits.

> _Celem obliczeń nie są liczby, lecz ich zrozumienie_ R.W. Hamming 1962.  


## Trochę historii

- Lata 60-te : Kolekcje danych, bazy danych, sieciowe DNBMS
- Lata 70-te : Relacyjne modele danych i ich implementacja w systemach OLTP
- Lata 80-te : Zaawansowane modele danych, extended-relational, objective oriented, aplikacyjno-zorientowane itp.
- Lata 90-te : Data mining, hurtownie danych, multimedialne bazy danych, systemy OLAP
- Później : NoSQL, Hadoop, SPARK, data lake

> Zna historię i filozofię modeli przetwarzania danych.

## Modele przetwarzania danych

Dane w biznesie przetwarzane są praktycznie od zawsze. W ciągu ostatnich dziesięcioleci ilość przetwarzanych danych systematycznie rośnie co wpływa na proces przygotowania i przetwarzania danych.

Większość danych przechowywana jest w bazach lub hurtowniach danych.
Standardowo dostęp do danych sprowadza się najczęściej do realizacji zapytań poprzez aplikacje.
Sposób wykorzystania i realizacji procesu dostępu do bazy danych nazywamy **modelem przetwarzania**.
Najczęściej używane są dwie implementacje:

### Model Tradycyjny

**Model tradycyjny** - przetwarzanie transakcyjne w trybie on-line, OLTP (on-line transaction processing).
Świetnie sprawdza się w przypadku obsługi bieżącej np. obsługa klienta, rejestr zamówień, obsługa sprzedaży itp.
Wykorzystywany w systemach Enterprise Resource Planning (ERP) Systems, Customer Relationship Management (CRM) software, and web-based applications.

<img alt="OLTP system" src="../img/baza1.png" align="center" />

Model ten dostarcza efektywnych rozwiązań do:

- efektywne i bezpieczne przechowywanie danych,
- transakcyjne odtwarzanie danych po awarii,
- optymalizacja dostępu do danych,
- zarządzanie współbierznością,
- przetwarzanie zdarzeń -> odczyt -> zapis

Aktualnie wiele działających aplikacji (nawet w jednym obszarze)
 realizuje się jako mikroserwisy, czyli małe i niezależne aplikacje (filozofia programowania LINUX - rób mało ale dobrze).

A co w przypadky gdy mamy doczynienia z:

- agregacjami danych z wielu systemów (np. dla wielu sklepów),
- wspomaganie analizy danych,
- raportowanie i podsumowania danych,
- optymalizacja złożonych zapytań,
- wpomaganie decyzji biznesowych.

Badania nad tego typu zagadnieniami doprowadziły do sformułowania nowego modelu przetwarzania danych oraz nowego typu baz danych - **Hurtownie Danych** _(Data warehouse)_.

### Model OLAP

**Przetwarzanie analityczne on-line OLAP (on-line analytic processing).**

 Wspieranie procesów analizy i dostarczanie narzędzi umożliwiających analizę wielowymiarową (czas, miejsce, produkt).

 Proces zrzucania danych z różnych systemów do jednej bazy nazywamy Extract-Transform-Load (ETL) (normalizacja i encoding and schema transaction).

 Analiza danych z hurtowni to przede wszystkim obliczanie **agregatów** (podsumowań) dotyczących wymiarów hurtowni.
 Proces ten jest całkowicie sterowany przez użytkownika.

**Przykład**

Załóżmy, że mamy dostęp do hurtowni danych gdzie przechowywane są informacje dotyczące sprzedaży produktów w supermarkecie.
Jak przeanalizować zapytania:

1. Jaka jest łączna sprzedaż produktów w kolejnych kwartałach, miesiącach, tygodniach ?
2. Jaka jest sprzedaż produktów z podziałem na rodzaje produktów ?
3. Jaka jest sprzedaż produktów z podziałem na oddziały supermarketu ?

Odpowiedzi na te pytania pozwalają określić `wąskie gardła` sprzedaży produktów przynoszących deficyt, zaplanować zapasy w magazynach czy porównać sprzedaż różnych grup w różnych oddziałach supermarketu.

W ramach Hurtowni Danych najczęściej wykonuje się dwa rodzaje zapytań:
1. Wykonywane okresowo w czasie zapytania raportowe obliczające biznesowe statystyki
2. Wykonywane ad-hoc zapytania wspomacające krytyczne decyzje biznesowe.

Oba wykonywane w trybie batchowym. Dziś ściśle wykonywane z użyciem technologii Hadoop.

<img alt="OLAP system" src="../img/baza2.png" align="center" />
